{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc.pilutil import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-66a52f512011>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED']=\"30\"\n",
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the batch_size here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validatiaon data creator with ablation\n",
    "# when ablation is 10, then 10 folders for each label will be selected.\n",
    "def get_data(path, ablation=None):\n",
    "    train_doc = np.random.permutation(open(path+'train.csv').readlines())\n",
    "    val_doc = np.random.permutation(open(path+'val.csv').readlines())\n",
    "    counts = np.zeros(5) # count for loading folders for 5 classes\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    # when ablation is None pass full training and val data\n",
    "    if ablation is not None:\n",
    "        # iterating train doc\n",
    "        for doc in train_doc:\n",
    "            lable = int(doc.strip().split(';')[2])\n",
    "            if counts[lable] < ablation:\n",
    "                train_data.append(doc)\n",
    "                counts[lable] += 1 \n",
    "        counts = np.zeros(5)\n",
    "        # iterating val doc\n",
    "        for doc in val_doc:\n",
    "            lable = int(doc.strip().split(';')[2])\n",
    "            if counts[lable] < ablation:\n",
    "                val_data.append(doc)\n",
    "                counts[lable] += 1\n",
    "    else:\n",
    "        train_data, val_data = train_doc, val_doc\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc, val_doc = get_data('Project_data/', ablation=None)\n",
    "batch_size = 32 # experiment with the batch size\n",
    "enable_augmentation = False # augmentation of Data\n",
    "# sequence ids\n",
    "# selecting alternate frames from 7 to 26.\n",
    "seq_idx = range(7,26,2)\n",
    "# image dimensions\n",
    "dim_x, dim_y = 120, 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with img_idx, y,z and normalization such that you get high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator with augmentation for train data\n",
    "def generator(source_path, folder_list, batch_size, is_train = False, augmention = False, debug=False):\n",
    "    # print('\\nSource path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = seq_idx #create a list of image numbers you want to use for a particular video\n",
    "    x = len(img_idx)\n",
    "    y, z = dim_x, dim_y\n",
    "    while True:\n",
    "        # doubling the data for augmentation\n",
    "        if is_train and augmention:\n",
    "            t = np.concatenate((np.random.permutation(folder_list), np.random.permutation(folder_list)))\n",
    "        else:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            \n",
    "        if (len(t)%batch_size) == 0:\n",
    "            num_batches = int(len(t)/batch_size)\n",
    "        else:\n",
    "            num_batches = len(t)//batch_size + 1\n",
    "            \n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                if debug:\n",
    "                    plt.figure(figsize=(20,5))\n",
    "                #handling remaining datapoints\n",
    "                folder_idx = folder + (batch*batch_size)\n",
    "                if folder_idx >= len(t):\n",
    "                    break\n",
    "                folder_str = t[folder_idx]\n",
    "                imgs = os.listdir(source_path+'/'+ folder_str.split(';')[0]) # read all the images in the folder\n",
    "                # randomly enabling augmentation and augmentation type\n",
    "                aug_type = None\n",
    "                if is_train and augmention and rn.randint(0,1) == 1:\n",
    "                    aug_type = rn.randint(0, 4) #randomly selecting augmentation type\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ folder_str.strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "\n",
    "                    # plotting original images for debugging purpose only\n",
    "                    if debug:\n",
    "                        plt.subplot(2, x, idx+1)\n",
    "                        plt.imshow(image.astype('uint8'))\n",
    "\n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    # making the rectangle images into square by cropping sides\n",
    "                    # so the aspect ration can be mantained while resizing.\n",
    "                    if image.shape[1] > image.shape[0]:\n",
    "                        diff_px = image.shape[1] - image.shape[0]\n",
    "                        crop_start = diff_px//2\n",
    "                        crop_end = crop_start + image.shape[0]\n",
    "                        image = image[:, crop_start:crop_end]\n",
    "                    elif image.shape[0] > image.shape[1]:\n",
    "                        diff_px = image.shape[0] - image.shape[1]\n",
    "                        crop_start = diff_px//2\n",
    "                        crop_end = crop_start + image.shape[1]\n",
    "                        image = image[:, crop_start:crop_end]\n",
    "\n",
    "                    resized_im = imresize(image, size=(y,z))\n",
    "\n",
    "                    if aug_type is not None:\n",
    "                        if aug_type == 0: # edge Enhancement\n",
    "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.EDGE_ENHANCE))\n",
    "                        elif aug_type == 1: # adding gaussian blur\n",
    "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.GaussianBlur(1)))\n",
    "                        elif aug_type == 2: # enchancing image detailing\n",
    "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.DETAIL))\n",
    "                        elif aug_type == 3: # sharpening image\n",
    "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.SHARPEN))\n",
    "                        elif aug_type == 4: # Brightness enhancement\n",
    "                            resized_im = np.array(ImageEnhance.Brightness((Image.fromarray(resized_im, 'RGB'))).enhance(1.5))\n",
    "                    # plotting rezised images for debugging purpose only\n",
    "                    if debug:\n",
    "                        plt.subplot(2, x, idx+x+1)\n",
    "                        plt.imshow(resized_im)\n",
    "\n",
    "                    batch_data[folder,idx,:,:,0] = resized_im[:,:,0]/255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = resized_im[:,:,1]/255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = resized_im[:,:,2]/255 #normalise and feed in the image\n",
    "\n",
    "                batch_labels[folder, int(folder_str.strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = 'Project_data/train' #'/notebooks/storage/Final_data/Collated_training/train'\n",
    "val_path =  'Project_data/val' #'/notebooks/storage/Final_data/Collated_training/val'\n",
    "\n",
    "#multiply number train seq by 2 when using augmentation\n",
    "multiplier = 1\n",
    "if enable_augmentation:\n",
    "    multiplier = 2\n",
    "num_train_sequences = len(train_doc)*multiplier\n",
    "print('# training sequences =', num_train_sequences)\n",
    "\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "\n",
    "num_epochs = 50 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing generative \n",
    "test_gen = generator(train_path, train_doc, 1, is_train = True, augmention = True, debug = True)\n",
    "d = next(test_gen)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you make the model using different functionalities that Keras provides. Remember to use Conv3D and MaxPooling3D and not Conv2D and Maxpooling2D for a 3D convolution model. You would want to use TimeDistributed while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Bidirectional, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, GlobalAveragePooling3D, ConvLSTM2D\n",
    "from keras.layers.convolutional import Conv2D, Conv3D, MaxPooling2D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "#input shape for the st layer\n",
    "input_shape = (len(seq_idx), dim_x, dim_y, 3)\n",
    "np.random.seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment -1 & 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(MaxPooling3D(pool_size=2))\n",
    "\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=2))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment - 3\n",
    "Con3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(3, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experminent -4\n",
    "Conv3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment - 5&6 \n",
    "Conv3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 7-8\n",
    "Con3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# #model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# #model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# #model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# #model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 9 (((11)))\n",
    "Time Distributed Conv2D+GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(32, (3,3), activation='relu'), input_shape=input_shape)\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(64, (3,3), activation='relu'))\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
    "# model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(GRU(128))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment -10\n",
    "TimeDistributed Conv2D+GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(32, (3,3), activation='relu'), input_shape=input_shape)\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(64, (3,3), activation='relu'))\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
    "# model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(GRU(128))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 11 Timedistributed + ConvLSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(8, (3,3), activation='relu'), input_shape=input_shape)\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(16, (3,3), activation='relu'))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(\n",
    "#     ConvLSTM2D(8, kernel_size = 3, return_sequences=False)\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(TimeDistributed(\n",
    "#     Dense(64, activation='relu'))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(\n",
    "    Conv2D(8, (3,3), activation='relu'), input_shape=input_shape)\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(\n",
    "    Conv2D(16, (3,3), activation='relu'))\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "model.add(\n",
    "    ConvLSTM2D(8, kernel_size = 3, return_sequences=False)\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(\n",
    "    Dense(64, activation='relu'))\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to compile the model. When you print the summary of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(lr=0.01) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size, is_train = True, augmention = enable_augmentation)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_exp_16' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001, verbose=1) # write the REducelronplateau code here\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                        callbacks=callbacks_list, validation_data=val_generator, \n",
    "                        validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1 = plt.plot(history.history['loss'])\n",
    "ax1 = plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower left')\n",
    "ax2 = plt.subplot(122)\n",
    "ax2 = plt.plot(history.history['categorical_accuracy'])\n",
    "ax2 = plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
